{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNlfWzbKIIHQPDGVK8zUZgv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suvanshhh/Object-Detection/blob/main/Detect_Track_and_count_with_YOLOV8_%26_Supervision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAqpaYl0SvsN",
        "outputId": "3d19a580-e408-4d52-cfce-b2f374cf333c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 15 09:47:22 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0              26W /  70W |    697MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mweAh2QsTbo6",
        "outputId": "b25f6761-b0d5-449d-a5ea-23b0bc3ccc12"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload Video"
      ],
      "metadata": {
        "id": "5ll9yaSTfSmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Video_Source =\"/content/cars.mp4\""
      ],
      "metadata": {
        "id": "Ibwt2MCfdwkz"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALLING YOLOv8"
      ],
      "metadata": {
        "id": "03QdVqtcfiO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUD0qCsPfnwG",
        "outputId": "9b4caabb-6806-4bb3-ac3c-bf3a75eb0c68"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.32)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.2.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.40)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6lURMhaftfY",
        "outputId": "6fe70673-e172-4fbe-8139-a9e05e05f308"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.32 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 30.8/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALL ByteTrack\n"
      ],
      "metadata": {
        "id": "1cFnX_qugE5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()"
      ],
      "metadata": {
        "id": "CxPXM2p6gAQS"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vSK6KxtkhZtH",
        "outputId": "08b59c6b-0bd0-46ea-a52f-b1ecd1deec33"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd {HOME}/ByteTrack\n",
        "\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
        "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
        "\n",
        "!pip3 install -q -r requirements.txt\n",
        "!python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/112 and https://github.com/roboflow/notebooks/issues/106\n",
        "!pip install -q loguru lap thop\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKb54_fYhclj",
        "outputId": "91509bb6-f4eb-4157-d440-bd0d368295c2"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolox.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass"
      ],
      "metadata": {
        "id": "8tKXYfRRhkYe"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALL Roboflow Supervision"
      ],
      "metadata": {
        "id": "TaXmB_hogT6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision==0.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5TnnOwUfMHv",
        "outputId": "fc892220-3e63-4dd0-f4ec-b945ad562e09"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: supervision==0.1.0 in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from supervision==0.1.0) (1.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from supervision==0.1.0) (4.8.0.76)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ5qsQ20gb2c",
        "outputId": "8e55b7f3-1c02-4c96-f180-042cc8cf56bc"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supervision.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Pre-trained YOLOv8 Model"
      ],
      "metadata": {
        "id": "Nos04J4bgn57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"yolov8x.pt\""
      ],
      "metadata": {
        "id": "R-SSvy8Egj3O"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuP5HwYugx-E",
        "outputId": "bb2191ad-70a4-49cc-d85e-48eaa4e3e8f6"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cthkILfFFPn",
        "outputId": "6795be34-3ff1-48a1-c658-48b8f7b00370"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ijw0euHCEBI1",
        "outputId": "f05e90be-1ac8-45ab-ae30-904370997c44"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=yolov8x.pt conf=0.25 source={Video_Source}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQOvTLCHF3kc",
        "outputId": "ee20b7a9-c417-4916-eb86-7187c1c6f121"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.32 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 591, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 453, in predict\n",
            "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\", line 183, in predict_cli\n",
            "    for _ in gen:  # sourcery skip: remove-empty-nested-block, noqa\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 35, in generator_context\n",
            "    response = gen.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\", line 226, in stream_inference\n",
            "    self.setup_source(source if source is not None else self.args.source)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\", line 198, in setup_source\n",
            "    self.dataset = load_inference_source(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\", line 202, in load_inference_source\n",
            "    dataset = LoadImagesAndVideos(source, batch=batch, vid_stride=vid_stride)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/loaders.py\", line 312, in __init__\n",
            "    self._new_video(videos[0])  # new video\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/loaders.py\", line 381, in _new_video\n",
            "    raise FileNotFoundError(f\"Failed to open video {path}\")\n",
            "FileNotFoundError: Failed to open video /content/cars.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.draw.color import ColorPalette"
      ],
      "metadata": {
        "id": "-gGabH2PIRa4"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAMES_DICT = model.model.names\n",
        "CLASS_NAMES_DICT\n"
      ],
      "metadata": {
        "id": "oR4UpR4WMf2x",
        "outputId": "62a62176-2f44-4840-f893-21a4255d4fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'person',\n",
              " 1: 'bicycle',\n",
              " 2: 'car',\n",
              " 3: 'motorcycle',\n",
              " 4: 'airplane',\n",
              " 5: 'bus',\n",
              " 6: 'train',\n",
              " 7: 'truck',\n",
              " 8: 'boat',\n",
              " 9: 'traffic light',\n",
              " 10: 'fire hydrant',\n",
              " 11: 'stop sign',\n",
              " 12: 'parking meter',\n",
              " 13: 'bench',\n",
              " 14: 'bird',\n",
              " 15: 'cat',\n",
              " 16: 'dog',\n",
              " 17: 'horse',\n",
              " 18: 'sheep',\n",
              " 19: 'cow',\n",
              " 20: 'elephant',\n",
              " 21: 'bear',\n",
              " 22: 'zebra',\n",
              " 23: 'giraffe',\n",
              " 24: 'backpack',\n",
              " 25: 'umbrella',\n",
              " 26: 'handbag',\n",
              " 27: 'tie',\n",
              " 28: 'suitcase',\n",
              " 29: 'frisbee',\n",
              " 30: 'skis',\n",
              " 31: 'snowboard',\n",
              " 32: 'sports ball',\n",
              " 33: 'kite',\n",
              " 34: 'baseball bat',\n",
              " 35: 'baseball glove',\n",
              " 36: 'skateboard',\n",
              " 37: 'surfboard',\n",
              " 38: 'tennis racket',\n",
              " 39: 'bottle',\n",
              " 40: 'wine glass',\n",
              " 41: 'cup',\n",
              " 42: 'fork',\n",
              " 43: 'knife',\n",
              " 44: 'spoon',\n",
              " 45: 'bowl',\n",
              " 46: 'banana',\n",
              " 47: 'apple',\n",
              " 48: 'sandwich',\n",
              " 49: 'orange',\n",
              " 50: 'broccoli',\n",
              " 51: 'carrot',\n",
              " 52: 'hot dog',\n",
              " 53: 'pizza',\n",
              " 54: 'donut',\n",
              " 55: 'cake',\n",
              " 56: 'chair',\n",
              " 57: 'couch',\n",
              " 58: 'potted plant',\n",
              " 59: 'bed',\n",
              " 60: 'dining table',\n",
              " 61: 'toilet',\n",
              " 62: 'tv',\n",
              " 63: 'laptop',\n",
              " 64: 'mouse',\n",
              " 65: 'remote',\n",
              " 66: 'keyboard',\n",
              " 67: 'cell phone',\n",
              " 68: 'microwave',\n",
              " 69: 'oven',\n",
              " 70: 'toaster',\n",
              " 71: 'sink',\n",
              " 72: 'refrigerator',\n",
              " 73: 'book',\n",
              " 74: 'clock',\n",
              " 75: 'vase',\n",
              " 76: 'scissors',\n",
              " 77: 'teddy bear',\n",
              " 78: 'hair drier',\n",
              " 79: 'toothbrush'}"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict and annotate single frame"
      ],
      "metadata": {
        "id": "v9lmUpy5M9zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "CLASS_ID = [2, 3, 5, 7]"
      ],
      "metadata": {
        "id": "iutaZLJEM8g7"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create frame generator\n",
        "generator = get_video_frames_generator(Video_Source)\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=2, text_thickness=2, text_scale=2)\n",
        "# acquire first video frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "# model prediction on single frame and conversion to supervision Detections\n",
        "results = model(frame)\n",
        "detections = Detections(\n",
        "    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "    confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "    class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        ")\n",
        "# format custom labels\n",
        "labels = [\n",
        "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "    for _, confidence, class_id, tracker_id\n",
        "    in detections\n",
        "]\n",
        "# annotate and display frame\n",
        "frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "\n",
        "%matplotlib inline\n",
        "show_frame_in_notebook(frame, (16, 16))"
      ],
      "metadata": {
        "id": "xXkqoXY_NGJV",
        "outputId": "e99ace56-02c1-418d-9826-8e7dd695abb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Could not open video at /content/cars.mp4",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-be0ec9264510>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# acquire first video frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# model prediction on single frame and conversion to supervision Detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/supervision/video/source.py\u001b[0m in \u001b[0;36mget_video_frames_generator\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not open video at {video_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Could not open video at /content/cars.mp4"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect_Track_and_count whole video"
      ],
      "metadata": {
        "id": "M9rxTQg6NtvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ],
      "metadata": {
        "id": "mu613cpvNxzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "y8TpsOgwN5fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Video_Source_1= \"/content/bike.mp4\""
      ],
      "metadata": {
        "id": "lYNeLKlWN9WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator\n",
        "from supervision.video.sink import VideoSink\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TWf5N3rLOACN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "LINE_START = Point(50, 1500)\n",
        "LINE_END = Point(3840-50, 1500)\n",
        "\n",
        "TARGET_VIDEO_PATH = \"bike.mp4\""
      ],
      "metadata": {
        "id": "b_tdsMg9OeXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VideoInfo.from_video_path(Video_Source_1)"
      ],
      "metadata": {
        "id": "8pMUkS4EO8-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections,\n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    tracker_ids = [None] * len(detections)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ],
      "metadata": {
        "id": "dZH07teqPHhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# create BYTETracker instance\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "# create VideoInfo instance\n",
        "video_info = VideoInfo.from_video_path(Video_Source_1)\n",
        "# create frame generator\n",
        "generator = get_video_frames_generator(Video_Source_1)\n",
        "# create LineCounter instance\n",
        "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
        "# create instance of BoxAnnotator and LineCounterAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "line_annotator = LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# open target video file\n",
        "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "    # loop over video frames\n",
        "  for frame in tqdm(generator, total=video_info.total_frames):\n",
        "        # model prediction on single frame and conversion to supervision Detections\n",
        "        results = model(frame)\n",
        "        detections = Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "        # filtering out detections with unwanted classes\n",
        "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # tracking detections\n",
        "        tracks = byte_tracker.update(\n",
        "            output_results=detections2boxes(detections=detections),\n",
        "            img_info=frame.shape,\n",
        "            img_size=frame.shape\n",
        "        )\n",
        "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "        detections.tracker_id = np.array(tracker_id)\n",
        "        # filtering out detections without trackers\n",
        "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # format custom labels\n",
        "        labels = [\n",
        "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "            for _, confidence, class_id, tracker_id\n",
        "            in detections\n",
        "        ]\n",
        "        # updating line counter\n",
        "        line_counter.update(detections=detections)\n",
        "        # annotate and display frame\n",
        "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "        line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
        "        sink.write_frame(frame)"
      ],
      "metadata": {
        "id": "qlLyOHiFPi2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C50XVk9RP3xT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}